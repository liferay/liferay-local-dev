# global envs
client_extension_dir_key = os.environ.get("CLIENT_EXTENSION_DIR_KEY")
lfrdev_domain = os.environ.get("LFRDEV_DOMAIN")
repo = os.environ.get("LOCALDEV_REPO", "/repo")


# Function process_extension
def process_extension(
    name,
    projectPath,
    workload,
    targetPort,
    virtual_instance_id="dxp.%s" % lfrdev_domain,
    source_deps=[],
    objects=[],
    port_forwards=[],
    resource_deps=[],
    links=[],
    cpu="",
    memory="",
    envs=[],
    readyPath="",
    init_metadata="",
    schedule="",
):
    more_deps = []
    for source_dep in source_deps:
        more_deps.append("/workspace/%s/%s" % (projectPath, source_dep))

    gradlePath = projectPath.replace("/", ":")

    build_args = " ".join(
        [
            "/workspace/gradlew",
            "--project-dir",
            "/workspace",
            ":%s:clean" % gradlePath,
            ":%s:buildClientExtensionDockerImage" % gradlePath,
            "--stacktrace",
            "-PserviceId=%s" % name,
            "-PvirtualInstanceId=%s" % virtual_instance_id,
            "-PlfrdevDomain=%s" % lfrdev_domain,
            "-PimageId=$EXPECTED_REF",
        ]
    )

    custom_build(
        name,
        build_args,
        deps=[
            "/workspace/%s/Dockerfile" % projectPath,
            "/workspace/%s/assets" % projectPath,
            "/workspace/%s/build.gradle" % projectPath,
            "/workspace/%s/client-extension.yaml" % projectPath,
            "/workspace/%s/src" % projectPath,
        ]
        + more_deps,
        ignore=[],
    )

    deploy_env = {
        "CPU": cpu,
        "ENVS": str(envs),
        "LFRDEV_DOMAIN": lfrdev_domain,
        "LOCALDEV_REPO": repo,
        "MEMORY": memory,
        "NAME": name,
        "PROJECT_PATH": projectPath,
        "READY_PATH": readyPath,
        "TARGET_PORT": str(targetPort),
        "VIRTUAL_INSTANCE_ID": virtual_instance_id,
        "INIT_METADATA": init_metadata,
        "WORKLOAD": workload,
        "SCHEDULE": schedule,
    }

    k8s_custom_deploy(
        name,
        "%s/scripts/k8s/delete.py 2>/dev/null && %s/scripts/k8s/create.py"
        % (repo, repo),
        "%s/scripts/k8s/delete.py" % repo,
        deps=["/workspace/client-extensions/%s/build/clientExtension/" % projectPath],
        apply_env=deploy_env,
        delete_env=deploy_env,
        image_deps=[name],
    )

    k8s_resource(
        labels=["Extensions"],
        port_forwards=port_forwards,
        objects=objects,
        resource_deps=["dxp.%s" % lfrdev_domain] + resource_deps,
        workload=name,
        links=links,
    )


# returns a array of paths that matched the search
# .gitignores and some common paths are ignored
def workspace_search(pattern):
    find_args = [
        "fdfind",
        "--exclude '*/build/'",
        "--exclude '*/node_modules/'",
        "--exclude '*/node_modules_cache/'",
        "--glob '%s'" % pattern,
        "/workspace/client-extensions",
        "2>/dev/null",
    ]
    return str(local(" ".join(find_args))).splitlines()


# main code

# global vars that can be overridden
dxp_buildargs = {}
dxp_data_volume = None
dxp_envs = {}
dxp_resource_deps = []
user_tiltfiles = []

for user_tiltfile in workspace_search("Tiltfile*"):
    symbols = load_dynamic(user_tiltfile)

    # load extension symbols from user's workspace Tiltfile
    if symbols.get("dxp_data_volume"):
        if dxp_data_volume == None:
            dxp_data_volume = symbols["dxp_data_volume"]
        else:
            fail("dxp_data_volume alreadyed defined!")

    dxp_buildargs.update(symbols.get("dxp_buildargs", {}))
    dxp_envs.update(symbols.get("dxp_envs", {}))
    user_dxp_resource_deps = symbols.get("dxp_resource_deps", [])
    dxp_resource_deps += user_dxp_resource_deps

    user_tiltfiles.append(symbols)

# if user didn't define data volume, define one based on CLIENT_EXTENSION_DIR_KEY
if dxp_data_volume == None:
    dxp_data_volume = "dxp-data-%s" % client_extension_dir_key

# setup tilt
docker_prune_settings()
update_settings(max_parallel_updates=1)

# useful only when debugging
# watch_file("%s/k8s/endpoint/" % repo)
# watch_file("%s/k8s/workloads/" % repo)
# watch_file("%s/scripts/k8s/" % repo)

if config.tilt_subcommand == "down":
    local("kubectl delete cm -l lxc.liferay.com/metadataType=dxp")
    local("kubectl delete cm -l lxc.liferay.com/metadataType=ext-init")
    local("%s/scripts/dxp-stop.sh" % repo)

    # check user tiltfiles for a "extension_stop()" hook
    for user_tiltfile in user_tiltfiles:
        if user_tiltfile.get("on_down"):
            user_tiltfile["on_down"]()

# build and launch dxp

dxp_buildargs_val = ""
for key, value in dxp_buildargs.items():
    dxp_buildargs_val += " --build-arg %s=%s " % (key, value)

dxp_envs_val = ""
for key, value in dxp_envs.items():
    dxp_envs_val += " -e %s=%s " % (key, value)

local_resource(
    "dxp.%s" % lfrdev_domain,
    env={"DXP_BUILDARGS": dxp_buildargs_val},
    cmd="%s/scripts/dxp-build.sh" % repo,
    serve_env={
        "DXP_DATA_VOLUME": dxp_data_volume if dxp_data_volume != None else "",
        "DXP_ENVS": dxp_envs_val,
    },
    serve_cmd="%s/scripts/dxp-serve.sh" % repo,
    deps=["%s/docker/images/dxp-server" % repo],
    readiness_probe=probe(
        initial_delay_secs=120,
        timeout_secs=5,
        period_secs=5,
        failure_threshold=99,
        exec=exec_action(["%s/scripts/dxp-status.sh" % repo]),
    ),
    trigger_mode=TRIGGER_MODE_MANUAL,
    links=[
        link("https://dxp.%s" % lfrdev_domain),
        link("https://dxp.%s/o/api" % lfrdev_domain, "Liferay API Explorer"),
    ],
    labels=["DXP"],
    resource_deps=dxp_resource_deps,
)

# search for user client extension projects in user workspace

client_extension_yaml_files = workspace_search("client-extension.yaml")

tiltignores = str(
    read_file("/workspace/client-extensions/.tiltignore", "")
).splitlines()

# for each client extension project, read yaml and process the extension

for client_extension_yaml_file in client_extension_yaml_files:
    project_path = os.path.dirname(client_extension_yaml_file)
    client_extension_name = os.path.basename(project_path)
    project_relative_path = os.path.relpath(project_path, "/workspace/")

    if client_extension_name in tiltignores:
        continue

    client_extension_object = read_yaml(client_extension_yaml_file)

    # defaults
    cpu = "100m"
    envs = []
    links = []
    memory = "50Mi"
    resource_deps = []
    readyPath = ""
    targetPort = 80
    watch = []
    workload = "static"
    init_metadata = "false"
    schedule = "* * * * *"

    # check for a LCP.json to determine workload type
    # if LCP.json doesn't exist then just default to "static" workload
    lcp_json_file = "%s/LCP.json" % project_path

    # check if lcp.json exists
    if os.path.exists(lcp_json_file):
        lcp_json = read_json(lcp_json_file)
        kind = lcp_json.get("kind", None)
        if kind == "Deployment":
            workload = "deployment"
        elif kind == "Job":
            workload = "job"
        elif kind == "CronJob":
            workload = "cronjob"
            schedule = lcp_json.get("schedule", "* * * * *")
        lcpMemory = lcp_json.get("memory", None)
        if lcpMemory:
            memory = "%sM" % lcpMemory
        lcpCpu = lcp_json.get("cpu", None)
        if lcpCpu:
            cpu = "%s" % lcpCpu
        lcpEnv = lcp_json.get("env", None)
        if lcpEnv:
            envs = lcpEnv

    if workload != "job":
        links = [link("https://%s.%s" % (client_extension_name, lfrdev_domain))]

    if client_extension_object.get("runtime"):
        runtime = client_extension_object["runtime"]

        readyPath = runtime.get("readyPath", "")

        if runtime.get("deps"):
            resource_deps = [runtime["deps"][0]]

        if runtime.get("port"):
            targetPort = runtime["port"]

        if runtime.get("watch"):
            watch = runtime["watch"]

    for key in client_extension_object:
        client_extension = client_extension_object.get(key)
        if type(client_extension) == "dict":
            client_extension_type = client_extension.get("type", None)
            if client_extension_type and client_extension_type.startswith(
                "oAuthApplication"
            ):
                init_metadata = "true"
                break

    # TODO call a script that can expand globs that may be passed into watch property
    # paths=local(/repo/scripts/unroll-globs.sh watch)
    # source_deps=paths

    process_extension(
        client_extension_name,
        project_relative_path,
        source_deps=watch,
        targetPort=targetPort,
        workload=workload,
        cpu=cpu,
        memory=memory,
        envs=envs,
        resource_deps=resource_deps,
        links=links,
        readyPath=readyPath,
        init_metadata=init_metadata,
        schedule=schedule,
    )

# if user Tiltfile defines an after_all, call it
for user_tiltfile in user_tiltfiles:
    if user_tiltfile.get("after_all"):
        user_tiltfile["after_all"]()
